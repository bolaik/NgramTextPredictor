# NgramTextPredictor
Coursera data science capstone project: R n-gram text predictor, shiny app

- See [Word Prediction: Exploratory Data Analysis](http://rpubs.com/bolaik/252703) for a introduction of the details of the methods. The first model use about 5% of the whole training dataset.

- The final model uses around 10% of the whole training dataset, resulting in a 10% top one precision, 15% top three precision. The `data.table` is used to process data frames, making the prediction process faster.

- See the [Shiny App](https://bolaik.shinyapps.io/n-gram_text_predictor/) for a demo.

- See these [slides](http://rpubs.com/bolaik/264417) for a brief explanation of the project.

## Helpful links (keeps adding)

- <https://github.com/bolaik/NLP-A-Model-to-Predict-Word-Sequences-jgendron>
- <https://github.com/bolaik/Coursera-capstone-project-vikasgupta1812>
- <https://github.com/bolaik/Capstone-Predict-Next-Word-momobo>
- <https://github.com/ThachNgocTran/KatzBackOffModelImplementationInR>

